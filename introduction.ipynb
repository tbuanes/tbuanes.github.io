{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: Introduction\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a large number of tools that let you easily set up and train a neural network or other machine learning (ML) model to analyse a data set. Such models *may* give good results, \n",
    "but to understand whether they really do, a critical evaluation should be performed. We will see that an ML model may classify over 99% of all instances correct, and still be completely useless. In other cases 80% correct may be a great result. It all depends on the problem at hand - and it is critical to consider the nature of the problem when evaluating what is a good result. The first part of this module will discuss how to evaluate the performance of a trained ML model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Typically in a classification task, the final layer applies a sigmoid (or softmax if multiclass) function that transforms the output to a number between 0 and 1. This number is often interpreted as a probability for the instance to belong to a certain class, but this is *generally not true*. Allthough a well-trained model should output a number which is such that closer to 1 means more probable to be of that class, there is no reason to expect a linear relation between the ML output and the probability of belonging to the class. If the exact probability isn't of importance to us, we may get away with using the ML output as it is - but remember to not confuse it with a probability. However, there are many cases where \"more likely to be of this class\" isn't good enough. In such cases we can attempt to calibrate the output to actually approximate the true probability. This discussion is the topic of the second part of the module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume you have a well-trained, well-calibrated ML model. If the model outputs 90% probability for an instance to belong to class A, are you then sure that you can trust this number? In general there are a lot of sources of uncertainty/randomness, both relating to measurement of the input features used in training the model, in selection of training data, and in the process of setting up and training the ML model. If the classification is important, we should not only care about the probability assingned by the model, but also how certain this probability is. Whether an instance is evaluated to belong to class A with $(90\\pm 1)\\%$ probability or with $(90^{+10}_{-30})\\%$ probability may make a major difference. This discussion is the topic of the third part of the module."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
